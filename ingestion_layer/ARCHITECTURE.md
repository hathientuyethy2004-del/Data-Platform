# ðŸ—ï¸ INGESTION LAYER - Architecture & Design

## System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DATA PLATFORM - Three-Layer Architecture                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  Layer 1: DATA SOURCES LAYER (simulations/)                        â”‚
â”‚  â”œâ”€â”€ Mobile App Simulator (Kafka Producer)                         â”‚
â”‚  â”œâ”€â”€ Web App Simulator                                             â”‚
â”‚  â”œâ”€â”€ PostgreSQL CDC Simulator                                      â”‚
â”‚  â”œâ”€â”€ Clickstream Simulator                                         â”‚
â”‚  â””â”€â”€ External Data Simulator                                       â”‚
â”‚          â†“ (Produce Data)                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚ KAFKA CLUSTER (7.5.0)                     â”‚                     â”‚
â”‚  â”‚ â”œâ”€â”€ topic_app_events                      â”‚                     â”‚
â”‚  â”‚ â”œâ”€â”€ topic_cdc_changes                     â”‚                     â”‚
â”‚  â”‚ â”œâ”€â”€ topic_clickstream                     â”‚                     â”‚
â”‚  â”‚ â”œâ”€â”€ topic_external_data                   â”‚                     â”‚
â”‚  â”‚ â””â”€â”€ Schema Registry                       â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚          â†“ (Consume Data) â† YOU ARE HERE                           â”‚
â”‚  Layer 2: INGESTION LAYER (ingestion_layer/) âœ¨                    â”‚
â”‚  â”œâ”€â”€ App Events Consumer (parallelized)                            â”‚
â”‚  â”œâ”€â”€ CDC Changes Consumer                                          â”‚
â”‚  â”œâ”€â”€ Clickstream Consumer                                          â”‚
â”‚  â”œâ”€â”€ External Data Consumer                                        â”‚
â”‚  â””â”€â”€ Unified Consumer (all topics)                                 â”‚
â”‚  â”œâ”€â”€ Data Validator (schema validation)                            â”‚
â”‚  â”œâ”€â”€ Metrics Collector (performance tracking)                      â”‚
â”‚  â””â”€â”€ Health Checker (system monitoring)                            â”‚
â”‚          â†“ (Validated Data)                                        â”‚
â”‚  Layer 3: PROCESSING LAYER (future)                                â”‚
â”‚  â”œâ”€â”€ Spark Streaming (real-time agg)                               â”‚
â”‚  â”œâ”€â”€ Airflow DAGs (batch processing)                               â”‚
â”‚  â””â”€â”€ Incremental Processing                                        â”‚
â”‚          â†“ (Processed Data)                                        â”‚
â”‚  Layer 4: STORAGE LAYER (future)                                   â”‚
â”‚  â”œâ”€â”€ Data Warehouse (BigQuery/Snowflake)                           â”‚
â”‚  â”œâ”€â”€ Data Lake (S3/HDFS)                                           â”‚
â”‚  â””â”€â”€ Real-time views (ClickHouse/Druid)                            â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## INGESTION LAYER Deep Design

### 1. Consumer Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ORCHESTRATOR (Main)                         â”‚
â”‚  IngestionLayerOrchestrator                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                           â”‚              â”‚              â”‚
    â†“                           â†“              â†“              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Consumer 1 â”‚  â”‚ Consumer 2 â”‚ â”‚Consumer3 â”‚ â”‚Consumer4 â”‚  â”‚Consumer5 â”‚
â”‚ (Thread)   â”‚  â”‚ (Thread)   â”‚ â”‚(Thread)  â”‚ â”‚(Thread)  â”‚  â”‚(Thread)  â”‚
â”‚            â”‚  â”‚            â”‚ â”‚          â”‚ â”‚          â”‚  â”‚          â”‚
â”‚ Topic:     â”‚  â”‚ Topic:     â”‚ â”‚Topic:    â”‚ â”‚Topic:    â”‚  â”‚Topic:    â”‚
â”‚ app_events â”‚  â”‚cdc_changes â”‚ â”‚click     â”‚ â”‚ext_data  â”‚  â”‚unified   â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
    â”‚                â”‚              â”‚            â”‚             â”‚
    â†“                â†“              â†“            â†“             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Kafka Broker (topic subscription)                    â”‚
â”‚   offset:0        offset:1000      offset:2500               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Message Processing Flow

```
INPUT: Kafka Message
  â†“
[1] CONSUME: Read from Kafka
  - topic_app_events
  - topic_cdc_changes
  - topic_clickstream
  - topic_external_data
  â†“
[2] PARSE: Extract JSON payload
  - Deserialize message
  - Extract metadata (topic, partition, offset)
  â†“
[3] VALIDATE: Check data quality
  â”œâ”€ Required fields present?
  â”œâ”€ Correct data types?
  â”œâ”€ Within business constraints?
  â””â”€ Valid timestamps?
  â†“
[4] ENRICH: Add metadata
  - __topic__ (source topic)
  - __partition__ (kafka partition)
  - __offset__ (kafka offset)
  - __timestamp__ (ingestion time)
  â†“
[5] BATCH: Accumulate messages
  - Buffer up to batch_size messages
  - Or timeout after batch_timeout_ms
  â†“
[6] METRICS: Collect performance data
  - Processing latency
  - Message throughput
  - Error rates
  - Per-topic statistics
  â†“
OUTPUT: Validated & Enriched Messages
```

### 3. Data Validation Pipeline

```
message = {
    "event_type": "page_view",
    "user_id": "user123",
    "session_id": "sess456",
    "timestamp": "2026-02-16T12:00:00Z",
    "app_type": "web"
}
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SCHEMA VALIDATION                  â”‚
â”‚ Check: VALIDATION_SCHEMAS          â”‚
â”‚   âœ“ event_type in required fields  â”‚
â”‚   âœ“ user_id is string              â”‚
â”‚   âœ“ session_id is string           â”‚
â”‚   âœ“ timestamp is ISO format        â”‚
â”‚   âœ“ app_type is string             â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“ (if all âœ“)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CONSTRAINT VALIDATION              â”‚
â”‚ Check: event constraints           â”‚
â”‚   âœ“ event_type in enum             â”‚
â”‚   âœ“ app_type in enum               â”‚
â”‚   âœ“ user_id length OK              â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“ (if all âœ“)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BUSINESS RULE VALIDATION           â”‚
â”‚ Check: domain logic                â”‚
â”‚   âœ“ Timestamp not in future        â”‚
â”‚   âœ“ Required context present       â”‚
â”‚   âœ“ Coherent state transitions     â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“ (if all âœ“)
âœ… VALID: Record metric, forward to next layer
     â†“ (if any âœ—)
âŒ INVALID: Log error, send to Dead Letter Queue
```

### 4. Metrics Collection

```
MetricsCollector (5-minute rolling window)
â”œâ”€â”€ Throughput Calculation
â”‚   â”œâ”€ Overall: messages/sec
â”‚   â”œâ”€ Per-topic: messages/sec
â”‚   â””â”€ Per-consumer-group: messages/sec
â”‚
â”œâ”€â”€ Latency Calculation
â”‚   â”œâ”€ Min: fastest processing
â”‚   â”œâ”€ Avg: mean processing time
â”‚   â”œâ”€ Max: slowest processing
â”‚   â”œâ”€ P95: 95th percentile (tail latency)
â”‚   â””â”€ P99: 99th percentile (worst cases)
â”‚
â”œâ”€â”€ Error Tracking
â”‚   â”œâ”€ Validation errors
â”‚   â”œâ”€ Processing errors
â”‚   â”œâ”€ Error rate %
â”‚   â””â”€ Error count per type
â”‚
â””â”€â”€ Message Size Statistics
    â”œâ”€ Min/Avg/Max size
    â”œâ”€ Total bytes processed
    â””â”€ Bandwidth estimation
```

### 5. Health Check System

```
HealthCheck (every 30 seconds)
â”œâ”€ Error Rate Check
â”‚  â””â”€ Alert if > 5%
â”‚
â”œâ”€ Latency Check
â”‚  â”œâ”€ Max latency
â”‚  â”œâ”€ Average latency
â”‚  â””â”€ Alert if max > 10s
â”‚
â”œâ”€ Throughput Check
â”‚  â”œâ”€ Messages/sec
â”‚  â””â”€ Alert if < 1 msg/sec
â”‚
â””â”€ Overall Status
   â”œâ”€ Healthy: all checks pass
   â”œâ”€ Warning: 1-2 checks warn
   â””â”€ Unhealthy: critical issues
```

---

## ðŸ”„ Consumer Groups Design

### Consumer Group 1: App Events Consumer

```
Group ID: app_events_consumer
Topics: [topic_app_events]
Purpose: Consume user events from mobile/web apps

Data Flow:
  Mobile Simulator ---\
                       â”œâ†’ topic_app_events â†’ app_events_consumer
  Web Simulator -------/

Event Examples:
{
  "event_type": "page_view",
  "user_id": "user123",
  "session_id": "s456",
  "timestamp": "2026-02-16T12:00:00Z",
  "app_type": "web",
  "properties": {
    "page": "/hotels",
    "duration_ms": 2500
  }
}
```

### Consumer Group 2: CDC Consumer

```
Group ID: cdc_consumer
Topics: [topic_cdc_changes]
Purpose: Consume database change events (CDC)

Data Flow:
  CDC Simulator â†’ topic_cdc_changes â†’ cdc_consumer

Event Examples:
{
  "op": "i",  // insert
  "table": "users",
  "before": null,
  "after": {
    "id": 123,
    "name": "John"
  },
  "ts_ms": 1645000000000
}
```

### Consumer Group 3: Clickstream Consumer

```
Group ID: clickstream_consumer
Topics: [topic_clickstream]
Purpose: Consume navigation & click events

Data Flow:
  Clickstream Simulator â†’ topic_clickstream â†’ clickstream_consumer

Event Examples:
{
  "event_id": "evt_789",
  "user_id": "user123",
  "page_url": "https://example.com/hotels",
  "event_type": "click",
  "timestamp": "2026-02-16T12:00:00Z",
  "element_id": "btn_book"
}
```

### Consumer Group 4: External Data Consumer

```
Group ID: external_data_consumer
Topics: [topic_external_data]
Purpose: Consume enrichment data (weather, location, etc)

Data Flow:
  External Data Simulator â†’ topic_external_data â†’ external_data_consumer

Event Examples:
{
  "data_source": "weather",
  "timestamp": "2026-02-16T12:00:00Z",
  "data": {
    "city": "Hanoi",
    "temperature": 25,
    "humidity": 70
  }
}
```

### Consumer Group 5: Unified Consumer

```
Group ID: unified_consumer
Topics: [all topics]
Purpose: Consume from all sources for unified processing

Data Flow:
  â”Œâ”€ topic_app_events â”€â”€â”
  â”œâ”€ topic_cdc_changes  â”œâ†’ unified_consumer
  â”œâ”€ topic_clickstream  â”‚
  â””â”€ topic_external_dataâ”˜

Use Case: Correlate events across all sources
         for comprehensive analysis
```

---

## ðŸ“Š Monitoring & Observability

### Metrics Collected

```
Per Message:
â”œâ”€ Processing time (ms)
â”œâ”€ Message size (bytes)
â”œâ”€ Validation success/failure
â”œâ”€ Topic
â”œâ”€ Timestamp

Aggregated (5-min window):
â”œâ”€ Throughput (msgs/sec)
â”œâ”€ Latency percentiles (p95, p99)
â”œâ”€ Error rate (%)
â”œâ”€ Total messages
â””â”€ By-topic breakdowns
```

### Health Indicators

```
Green (Healthy):
â”œâ”€ Error rate < 1%
â”œâ”€ Avg latency < 10ms
â””â”€ Throughput > 10 msgs/sec

Yellow (Warning):
â”œâ”€ Error rate 1-5%
â”œâ”€ Avg latency 10-50ms
â””â”€ Throughput 5-10 msgs/sec

Red (Critical):
â”œâ”€ Error rate > 5%
â”œâ”€ Avg latency > 50ms
â””â”€ Throughput < 5 msgs/sec
```

---

## ðŸ” Error Handling

### Validation Errors

```
Input: {"user_id": "u1", "session_id": "s1"}
       (missing event_type)
       â†“
Error: Missing required field: event_type
       â†“
Action: Count error, log, skip message
Result: Error rate increases, message not processed
```

### Processing Errors

```
Input: Exception in message processing
       â†“
Error: Consumer lag, throughput drop
       â†“
Action: Retry with backoff
        Max 3 attempts before skip
Result: Alert triggered
```

### Recovery Strategy

```
[Error Detected]
  â†“
[Retry Attempt 1] (wait 1s)
  â†“ fail
[Retry Attempt 2] (wait 2s)
  â†“ fail
[Retry Attempt 3] (wait 4s)
  â†“ fail
[Log Error] â†’ Send to Dead Letter Queue
[Continue] â†’ Process next message
```

---

## ðŸš€ Scaling & Performance

### Horizontal Scaling

```
Single Instance Performance:
  Throughput: ~50 msgs/sec
  Latency: 5-10ms avg
  CPU: 30-40%
  Memory: 256MB

With 5 Parallel Consumers:
  Throughput: ~250 msgs/sec  (5x)
  Latency: 5-10ms avg (same)
  CPU: 40-50% per container
  Memory: 256MB per container
```

### Bottleneck Analysis

```
Throughput Limited By:
1. Kafka fetch size (max.poll.records)
   Current: 500 msgs/poll
   â†’ Increase to 1000 for 2x throughput

2. Batch timeout
   Current: 5000ms
   â†’ Decrease to 1000ms for lower latency

3. Validation complexity
   Current: Full schema + constraint
   â†’ Disable non-critical checks

4. Metrics collection overhead
   Current: Every message
   â†’ Sample 1% for high throughput
```

---

## ðŸ”„ Graceful Shutdown

```
[SIGTERM Received]
  â†“
Set shutdown_event
  â†“
Stop accepting new messages
  â†“
Process remaining buffered messages
  â†“
Close consumer connections
  â†“
Wait for all threads (timeout 5s)
  â†“
Print final statistics
  â†“
Exit(0)
```

---

## Integration Points

### Upstreams (Data Sources)

```
DATA SOURCES LAYER
â”œâ”€â”€ Mobile Simulator â†’ Kafka â†’ topic_app_events
â”œâ”€â”€ Web Simulator â†’ Kafka â†’ topic_app_events
â”œâ”€â”€ CDC Simulator â†’ Kafka â†’ topic_cdc_changes
â”œâ”€â”€ Clickstream Simulator â†’ Kafka â†’ topic_clickstream
â””â”€â”€ External Data Simulator â†’ Kafka â†’ topic_external_data
```

### Downstreams (Used By)

```
PROCESSING LAYER (future)
â”œâ”€â”€ Spark Streaming â† INGESTION LAYER metrics
â”œâ”€â”€ Airflow DAGs â† INGESTION LAYER validated data
â””â”€â”€ Feature Store â† INGESTION LAYER processed data
```

---

**Architecture Version:** 1.0  
**Last Updated:** February 16, 2026  
**Status:** âœ… Production Ready
